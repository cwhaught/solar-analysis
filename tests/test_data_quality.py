"""
Tests for Data Quality Analysis Utilities

Tests for DataQualityChecker that standardizes data validation
and quality reporting across notebooks.
"""

import pytest
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from unittest.mock import Mock, patch

# Add src to path for imports
import sys
sys.path.append('src')

from src.data.quality import DataQualityChecker


class TestDataQualityChecker:
    """Test the DataQualityChecker utility"""

    def setup_method(self):
        """Set up test fixtures"""
        self.checker = DataQualityChecker()

        # Create sample clean data
        dates = pd.date_range('2023-01-01', periods=100, freq='15min')
        # Create realistic, consistent energy data
        production = np.random.uniform(0, 5, 100)
        consumption = np.random.uniform(0.5, 2, 100)
        # Calculate export/import based on production-consumption balance
        export = np.maximum(0, production - consumption)
        import_energy = np.maximum(0, consumption - production)

        self.clean_data = pd.DataFrame({
            'Production (kWh)': production,
            'Consumption (kWh)': consumption,
            'Export (kWh)': export,
            'Import (kWh)': import_energy
        }, index=dates)

        # Create sample problematic data
        self.problem_data = self.clean_data.copy()
        # Add missing values
        self.problem_data.loc[self.problem_data.index[10:15], 'Production (kWh)'] = np.nan
        # Add negative production
        self.problem_data.loc[self.problem_data.index[20], 'Production (kWh)'] = -1.0
        # Add export exceeding production
        self.problem_data.loc[self.problem_data.index[30], 'Export (kWh)'] = 10.0
        self.problem_data.loc[self.problem_data.index[30], 'Production (kWh)'] = 2.0

    def test_init(self):
        """Test checker initialization"""
        checker = DataQualityChecker()
        assert checker.energy_columns == [
            'Production (kWh)', 'Consumption (kWh)',
            'Export (kWh)', 'Import (kWh)'
        ]

        custom_cols = ['Solar (kWh)', 'Load (kWh)']
        custom_checker = DataQualityChecker(energy_columns=custom_cols)
        assert custom_checker.energy_columns == custom_cols

    def test_check_completeness_clean_data(self):
        """Test completeness check with clean data"""
        result = self.checker.check_completeness(self.clean_data)

        assert isinstance(result, dict)
        assert 'overall_metrics' in result
        assert 'column_metrics' in result
        assert 'temporal_metrics' in result

        # Clean data should have 100% completeness
        overall = result['overall_metrics']
        assert overall['completeness_pct'] == 100.0
        assert overall['total_records'] == 100
        assert overall['total_columns'] == 4

        # Each column should be complete
        for col in self.clean_data.columns:
            col_metrics = result['column_metrics'][col]
            assert col_metrics['missing_count'] == 0
            assert col_metrics['completeness_pct'] == 100.0

    def test_check_completeness_with_missing_data(self):
        """Test completeness check with missing data"""
        result = self.checker.check_completeness(self.problem_data)

        overall = result['overall_metrics']
        assert overall['completeness_pct'] < 100.0

        # Production column should show missing values
        prod_metrics = result['column_metrics']['Production (kWh)']
        assert prod_metrics['missing_count'] == 5  # 5 NaN values added
        assert prod_metrics['completeness_pct'] == 95.0  # 95/100

    def test_check_completeness_temporal_metrics(self):
        """Test temporal completeness analysis"""
        result = self.checker.check_completeness(self.clean_data)

        temporal = result['temporal_metrics']
        assert 'expected_frequency' in temporal
        assert 'temporal_completeness_pct' in temporal
        assert 'expected_records' in temporal

        # Should detect 15-minute frequency
        assert '0:15:00' in temporal['expected_frequency']

    def test_check_missing_values(self):
        """Test missing values analysis"""
        result = self.checker.check_missing_values(self.problem_data)

        assert isinstance(result, dict)
        assert 'summary' in result
        assert 'patterns' in result
        assert 'recommendations' in result

        summary = result['summary']
        assert summary['columns_with_missing'] == 1  # Only Production has missing
        assert summary['total_missing_values'] == 5
        assert summary['worst_column'] == 'Production (kWh)'
        assert summary['worst_column_pct'] == 5.0

    def test_check_missing_values_recommendations(self):
        """Test missing values recommendations"""
        # Create data with high missing percentage
        high_missing_data = self.clean_data.copy()
        high_missing_data.iloc[:60, high_missing_data.columns.get_loc('Production (kWh)')] = np.nan  # 60% missing

        result = self.checker.check_missing_values(high_missing_data)
        recommendations = result['recommendations']

        assert len(recommendations) > 0
        # Should recommend dropping column with >50% missing
        assert any('dropping column' in rec.lower() for rec in recommendations)

    def test_check_data_integrity_clean_data(self):
        """Test data integrity check with clean data"""
        result = self.checker.check_data_integrity(self.clean_data)

        assert isinstance(result, dict)
        assert 'issues' in result
        assert 'warnings' in result
        assert 'summary' in result

        # Clean data should have no issues
        assert len(result['issues']) == 0
        summary = result['summary']
        assert summary['total_issues'] == 0
        assert summary['data_quality_score'] > 90  # Should have high score

    def test_check_data_integrity_with_issues(self):
        """Test data integrity check with problematic data"""
        result = self.checker.check_data_integrity(self.problem_data)

        # Should detect issues
        assert len(result['issues']) > 0

        # Check for negative production issue
        negative_issue = next((issue for issue in result['issues']
                              if issue['type'] == 'negative_production'), None)
        assert negative_issue is not None
        assert negative_issue['count'] == 1

        # Check for excess export issue
        excess_issue = next((issue for issue in result['issues']
                            if issue['type'] == 'excess_export'), None)
        assert excess_issue is not None
        assert excess_issue['count'] >= 1  # May be more than 1 due to random data

        # Quality score should be lower
        summary = result['summary']
        assert summary['data_quality_score'] < 90

    def test_check_data_integrity_energy_balance(self):
        """Test energy balance validation"""
        # Create data with energy balance issues
        balance_data = pd.DataFrame({
            'Production (kWh)': [10, 5, 8],
            'Consumption (kWh)': [8, 6, 7],
            'Export (kWh)': [3, 0, 2],  # 10-8=2, but export=3 (imbalance)
            'Import (kWh)': [0, 1, 0]
        }, index=pd.date_range('2023-01-01', periods=3, freq='D'))

        result = self.checker.check_data_integrity(balance_data)

        # Should detect energy balance warnings
        balance_warning = next((warning for warning in result['warnings']
                               if warning['type'] == 'energy_balance'), None)
        assert balance_warning is not None

    def test_generate_quality_report_clean_data(self):
        """Test quality report generation with clean data"""
        report = self.checker.generate_quality_report(self.clean_data)

        assert isinstance(report, str)
        assert "DATA QUALITY REPORT" in report
        assert "Dataset Overview" in report
        assert "Data Completeness" in report
        assert "Data Integrity" in report

        # Should indicate excellent quality
        assert "ðŸŸ¢ Excellent data quality" in report or "quality score" in report.lower()

    def test_generate_quality_report_problem_data(self):
        """Test quality report generation with problematic data"""
        report = self.checker.generate_quality_report(self.problem_data)

        assert "âš ï¸ Missing Values" in report
        assert "âŒ Critical Issues" in report
        assert "ðŸ’¡ Recommendations" in report

        # Should mention specific issues
        assert "negative production" in report.lower() or "missing" in report.lower()

    def test_generate_quality_report_without_recommendations(self):
        """Test quality report without recommendations"""
        report = self.checker.generate_quality_report(
            self.clean_data,
            include_recommendations=False
        )

        assert "ðŸ’¡ Recommendations" not in report
        assert "DATA QUALITY REPORT" in report

    def test_detect_outliers(self):
        """Test outlier detection functionality"""
        # Create data with obvious outliers
        data_with_outliers = self.clean_data.copy()
        data_with_outliers.loc[data_with_outliers.index[0], 'Production (kWh)'] = 100  # Huge outlier

        outlier_info = self.checker._detect_outliers(data_with_outliers['Production (kWh)'])

        assert outlier_info['count'] > 0
        assert len(outlier_info['indices']) > 0

    def test_detect_outliers_insufficient_data(self):
        """Test outlier detection with insufficient data"""
        small_series = pd.Series([1, 2])  # Less than 4 values
        outlier_info = self.checker._detect_outliers(small_series)

        assert outlier_info['count'] == 0
        assert outlier_info['indices'] == []

    def test_calculate_quality_score(self):
        """Test quality score calculation"""
        # Clean data should have high score
        integrity_clean = {'issues': [], 'warnings': []}
        score_clean = self.checker._calculate_quality_score(self.clean_data, integrity_clean)
        assert score_clean >= 95

        # Data with issues should have lower score
        integrity_issues = {
            'issues': [{'type': 'test_issue'}],
            'warnings': [{'type': 'test_warning'}, {'type': 'test_warning2'}]
        }
        score_issues = self.checker._calculate_quality_score(self.problem_data, integrity_issues)
        assert score_issues < score_clean

    def test_analyze_temporal_completeness(self):
        """Test temporal completeness analysis"""
        result = self.checker._analyze_temporal_completeness(self.clean_data)

        assert 'expected_frequency' in result
        assert 'temporal_completeness_pct' in result
        assert 'expected_records' in result

        # Should detect correct frequency and completeness
        assert result['temporal_completeness_pct'] <= 100.0

    def test_detect_time_gaps(self):
        """Test time gap detection"""
        # Create data with gaps
        dates_with_gap = list(pd.date_range('2023-01-01', periods=10, freq='15min'))
        # Remove some dates to create a gap
        dates_with_gap = dates_with_gap[:5] + dates_with_gap[8:]  # Skip 3 intervals

        gap_data = pd.DataFrame({
            'Production (kWh)': range(len(dates_with_gap))
        }, index=dates_with_gap)

        expected_freq = timedelta(minutes=15)
        gaps = self.checker._detect_time_gaps(gap_data, expected_freq)

        assert len(gaps) > 0  # Should detect the gap

    def test_error_handling(self):
        """Test error handling in quality checks"""
        # Test with empty DataFrame
        empty_df = pd.DataFrame()

        completeness = self.checker.check_completeness(empty_df)
        assert 'overall_metrics' in completeness

        missing = self.checker.check_missing_values(empty_df)
        assert 'summary' in missing

        integrity = self.checker.check_data_integrity(empty_df)
        assert 'summary' in integrity

    def test_custom_energy_columns(self):
        """Test checker with custom energy columns"""
        custom_checker = DataQualityChecker(['Solar (kWh)', 'Load (kWh)'])

        custom_data = pd.DataFrame({
            'Solar (kWh)': [5, -1, 3],  # Include negative value
            'Load (kWh)': [4, 4, 4],
            'Other': [1, 1, 1]
        }, index=pd.date_range('2023-01-01', periods=3, freq='D'))

        # Should still detect negative production in custom column
        integrity = custom_checker.check_data_integrity(custom_data)

        # Note: The current implementation looks for 'Production (kWh)' specifically
        # This test documents current behavior - may need enhancement for full custom support


class TestDataQualityIntegration:
    """Integration tests for data quality checking"""

    def test_realistic_solar_data_quality(self):
        """Test quality checking with realistic solar data patterns"""
        # Create realistic solar data with various quality issues
        dates = pd.date_range('2023-01-01', periods=1000, freq='15min')

        # Realistic production pattern
        production = []
        for date in dates:
            hour = date.hour + date.minute / 60
            if 6 <= hour <= 18:  # Daylight hours
                peak_factor = 1 - abs(hour - 12) / 6
                prod = max(0, peak_factor * 5) + np.random.normal(0, 0.5)
            else:
                prod = 0
            production.append(max(0, prod))  # Ensure non-negative

        consumption = np.random.uniform(0.8, 1.5, len(dates))
        export = [max(0, p - c) for p, c in zip(production, consumption)]
        import_energy = [max(0, c - p) for p, c in zip(production, consumption)]

        realistic_data = pd.DataFrame({
            'Production (kWh)': production,
            'Consumption (kWh)': consumption,
            'Export (kWh)': export,
            'Import (kWh)': import_energy
        }, index=dates)

        # Add some realistic quality issues
        # Missing data during maintenance
        realistic_data.loc[realistic_data.index[100:110], :] = np.nan

        # Sensor malfunction (negative reading)
        realistic_data.loc[realistic_data.index[200], 'Production (kWh)'] = -0.1

        checker = DataQualityChecker()

        # Test all quality checks
        completeness = checker.check_completeness(realistic_data)
        missing = checker.check_missing_values(realistic_data)
        integrity = checker.check_data_integrity(realistic_data)
        report = checker.generate_quality_report(realistic_data)

        # Should detect the issues we introduced
        assert completeness['overall_metrics']['completeness_pct'] < 100
        assert missing['summary']['total_missing_values'] > 0
        assert len(integrity['issues']) > 0
        assert "Missing Values" in report
        assert "Critical Issues" in report

    def test_quality_performance_large_dataset(self):
        """Test quality checking performance with large datasets"""
        import time

        # Create large dataset (1 year of 15-minute data)
        dates = pd.date_range('2023-01-01', periods=35040, freq='15min')  # 365 * 96
        large_data = pd.DataFrame({
            'Production (kWh)': np.random.uniform(0, 5, len(dates)),
            'Consumption (kWh)': np.random.uniform(0.5, 2, len(dates)),
            'Export (kWh)': np.random.uniform(0, 2, len(dates)),
            'Import (kWh)': np.random.uniform(0, 1.5, len(dates))
        }, index=dates)

        checker = DataQualityChecker()

        start_time = time.time()
        report = checker.generate_quality_report(large_data)
        check_time = time.time() - start_time

        # Should complete reasonably quickly (under 10 seconds for 1 year of data)
        assert check_time < 10.0
        assert isinstance(report, str)
        assert len(report) > 100  # Should generate substantial report

    def test_edge_cases(self):
        """Test edge cases and boundary conditions"""
        checker = DataQualityChecker()

        # Test with single row
        single_row = pd.DataFrame({
            'Production (kWh)': [1.0]
        }, index=[datetime.now()])

        completeness = checker.check_completeness(single_row)
        assert completeness['overall_metrics']['completeness_pct'] == 100.0

        # Test with all missing data
        all_missing = pd.DataFrame({
            'Production (kWh)': [np.nan, np.nan, np.nan]
        }, index=pd.date_range('2023-01-01', periods=3, freq='D'))

        missing_result = checker.check_missing_values(all_missing)
        assert missing_result['summary']['worst_column_pct'] == 100.0

        # Test with all zeros
        all_zeros = pd.DataFrame({
            'Production (kWh)': [0, 0, 0],
            'Consumption (kWh)': [1, 1, 1],
            'Export (kWh)': [0, 0, 0],
            'Import (kWh)': [1, 1, 1]
        }, index=pd.date_range('2023-01-01', periods=3, freq='D'))

        integrity_zeros = checker.check_data_integrity(all_zeros)
        # Should not flag zero production as an error (nighttime is normal)
        negative_issues = [issue for issue in integrity_zeros['issues']
                          if issue['type'] == 'negative_production']
        assert len(negative_issues) == 0